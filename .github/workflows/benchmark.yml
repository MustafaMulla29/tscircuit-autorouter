name: Autorouting Benchmark

on:
  issue_comment:
    types: [created]
  pull_request:
    types: [opened]

jobs:
  post-instructions:
    name: Post benchmark instructions
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - name: Post comment with benchmark instructions
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.pull_request.number,
              body: `## üèÉ Benchmark This PR

            Maintainers can run benchmarks on this PR by commenting:

            \`\`\`
            /benchmark [SolverName] [scenario-limit]
            \`\`\`

            **Examples:**
            - \`/benchmark\` - Run with default solver, all scenarios
            - \`/benchmark AutoroutingPipelineSolver3_HgPortPointPathing\` - Run with specific solver
            - \`/benchmark AutoroutingPipelineSolver3_HgPortPointPathing 10\` - Run with specific solver, 10 scenarios
            - \`/benchmark _ 20\` - Run with default solver, 20 scenarios`
            });

  benchmark:
    name: Run autorouting benchmark
    # Only run on PR comments with /benchmark command from maintainers (not bots)
    if: |
      github.event_name == 'issue_comment' &&
      github.event.issue.pull_request &&
      github.event.comment.user.type != 'Bot' &&
      contains(github.event.comment.body, '/benchmark') &&
      (
        github.event.comment.author_association == 'OWNER' ||
        github.event.comment.author_association == 'MEMBER' ||
        github.event.comment.author_association == 'COLLABORATOR'
      )
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: React to comment and post running status
        id: running-comment
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            await github.rest.reactions.createForIssueComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: context.payload.comment.id,
              content: 'rocket'
            });

            const comment = await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: `## üèÉ Autorouting Benchmark\n\n‚è≥ Running benchmark... [View progress](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`
            });
            core.setOutput('comment_id', comment.data.id);

      - name: Get PR branch and parse solver name
        id: pr-info
        uses: actions/github-script@v7
        with:
          script: |
            const pr = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });
            core.setOutput('ref', pr.data.head.ref);
            core.setOutput('sha', pr.data.head.sha);

            // Parse solver name and scenario limit from comment: /benchmark [SolverName] [limit]
            // Examples: /benchmark, /benchmark SolverName, /benchmark SolverName 50, /benchmark _ 50
            const comment = context.payload.comment.body;
            const match = comment.match(/\/benchmark(?:\s+(\S+))?(?:\s+(\d+))?/);
            const solverName = match && match[1] && match[1] !== '_' ? match[1] : '';
            const scenarioLimit = match && match[2] ? match[2] : '';
            core.setOutput('solver_name', solverName);
            core.setOutput('scenario_limit', scenarioLimit);

      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.pr-info.outputs.ref }}

      - name: Setup bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      - name: Build autorouter
        run: bun run build

      - name: Install benchmark CLI
        run: bun add -g @tscircuit/autorouting-dataset-01

      - name: Create solver entry file
        run: |
          cat > benchmark-solver.ts << 'EOF'
          export * from "./lib"
          EOF

      - name: Run benchmark
        id: benchmark
        run: |
          SOLVER_NAME="${{ steps.pr-info.outputs.solver_name }}"
          SCENARIO_LIMIT="${{ steps.pr-info.outputs.scenario_limit }}"

          # Build command with optional solver name and scenario limit
          CMD="autorouting-dataset-runner benchmark-solver.ts"

          if [ -n "$SOLVER_NAME" ]; then
            CMD="$CMD $SOLVER_NAME"
            echo "Running benchmark with solver: $SOLVER_NAME"
          else
            echo "Running benchmark with default solver"
          fi

          if [ -n "$SCENARIO_LIMIT" ]; then
            CMD="$CMD --scenario-limit $SCENARIO_LIMIT"
            echo "Scenario limit: $SCENARIO_LIMIT"
          else
            echo "Running all scenarios"
          fi

          # Run and capture output while showing live progress
          $CMD 2>&1 | tee /tmp/benchmark_output.txt || true

          # Extract only key info for the comment (to avoid "Argument list too long" error)
          {
            echo "BENCHMARK_OUTPUT<<EOFMARKER"
            # Get loading/using autorouter lines
            grep -E "^(Loading|‚úì Using|‚úì From)" /tmp/benchmark_output.txt || true
            echo ""
            # Get the results table (lines with + or |)
            grep -E "^[+|]" /tmp/benchmark_output.txt || true
            echo ""
            # Get summary lines
            grep -E "^(Scenarios:|‚úì)" /tmp/benchmark_output.txt | tail -3 || true
            echo "EOFMARKER"
          } >> $GITHUB_OUTPUT

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: results/
          retention-days: 30

      - name: Update comment with results
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const output = `${{ steps.benchmark.outputs.BENCHMARK_OUTPUT }}`;
            const solverName = '${{ steps.pr-info.outputs.solver_name }}' || 'default';
            const scenarioLimit = '${{ steps.pr-info.outputs.scenario_limit }}' || 'all';

            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: ${{ steps.running-comment.outputs.comment_id }},
              body: `## üèÉ Autorouting Benchmark Results

            **Solver:** ${solverName} | **Scenarios:** ${scenarioLimit}

            \`\`\`
            ${output}
            \`\`\`

            üìä [Download HTML visualization and bundle](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}#artifacts)

            <sub>Triggered by @${{ github.event.comment.user.login }} ‚Ä¢ Commit: ${{ steps.pr-info.outputs.sha }}</sub>`
            });